{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualizações"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EDA\n",
    "* Criar novas colunas\n",
    "* Criar Função que treine os modelos XGBosst e Random Forest e gere uma tabela com as metricas de ambos\n",
    "* Criar Função que função que treine o modelo escolhido e atualize a tabela de score das versões\n",
    "* Escolher outros valores para os parametros no fine tuning\n",
    "* Criar uma função que faça todas as transformações do dataset test.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflection\n",
    "import io\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as snb\n",
    "import time\n",
    "import sweetviz as sv\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "from boruta import BorutaPy\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from category_encoders import CountEncoder, TargetEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "snb.set_style('whitegrid')\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dtypes(df):\n",
    "    print(df.dtypes)\n",
    "    return None\n",
    "\n",
    "def show_dimensions(df):\n",
    "    print('Number of rows: {}' .format(df.shape[0]))\n",
    "    print('Number of columns: {}' .format(df.shape[1]))\n",
    "    return None\n",
    "\n",
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).to_numpy()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = stats.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    return round(np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) ),2)\n",
    "\n",
    "def train_models(x_train, x_test, y_train, y_test):\n",
    "\n",
    "    # Treinando modelo Random Forest\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(x_train, y_train)\n",
    "    rf_f1_score = f1_score(y_test, rf.predict(x_test))\n",
    "\n",
    "    # Treinando modelo XGBoost\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    xgb_f1_score = f1_score(y_test, xgb.predict(x_test))\n",
    "\n",
    "    # Criando a tabela com o nome do algoritmo e o f1_score\n",
    "    table = pd.DataFrame({'Algoritmo': ['Random Forest', 'XGBoost'], 'F1 Score': [\n",
    "                         rf_f1_score, xgb_f1_score]})\n",
    "\n",
    "    return table\n",
    "\n",
    "def transfomation_test(model, dft, listID, name = 'submission'):\n",
    "    # Rename \n",
    "    dft = dft.rename(columns={'id':'id','Classificação do hotel': 'hotel_rating', 'Meses da reserva até o check-in': 'month_booking',\n",
    "                            'Número de pernoites reservadas': 'number_stays_booking', 'Número de hospedes': 'number_guests',\n",
    "                            'Regime de alimentação': 'meal_regime', 'Nacionalidade': 'nationality', 'Forma de Reserva': 'reservation_Form',\n",
    "                            'Já se hospedou anterioremente': 'previously_hosted', 'Tipo do quarto reservado': 'type_booked_room',\n",
    "                            'Reserva feita por agência de turismo': 'tourism_agency_booking', 'Reserva feita por empresa': 'company_booking',\n",
    "                            'Reserva com Estacionamento': 'parking_Reservation', 'Reserva com Observações': 'reservation_Observations', 'Reserva Cancelada': 'booking_canceled'})\n",
    "\n",
    "\n",
    "\n",
    "    ## Fill NA\n",
    "    dft['nationality'] = dft['nationality'].apply(\n",
    "        lambda x: 'Spain' if pd.isnull(x) else x)\n",
    "    dft['number_guests'] = dft['number_guests'].apply(\n",
    "        lambda x: 1 if pd.isnull(x) else x)\n",
    "    dft['number_guests'] = dft['number_guests'].astype('int64')\n",
    "    ## Change type\n",
    "    dft['id'] = dft['id'].astype('int64')\n",
    "\n",
    "    ## Rescaling\n",
    "    rs = RobustScaler()\n",
    "\n",
    "    # meses_da_reserva_ate_o_check-in - Robust Scaler\n",
    "    dft['id'] = rs.fit_transform( dft[['id']].values )\n",
    "\n",
    "    # meses_da_reserva_ate_o_check-in - Robust Scaler\n",
    "    dft['month_booking'] = rs.fit_transform(dft[['month_booking']].values)\n",
    "\n",
    "    # numero_de_pernoites_reservadas - Robust Scaler\n",
    "    dft['number_stays_booking'] = rs.fit_transform( dft[['number_stays_booking']].values )\n",
    "\n",
    "    # numero_de_hospedes - Robust Scaler\n",
    "    dft['number_guests'] = rs.fit_transform( dft[['number_guests']].values )\n",
    "    ## Transformation\n",
    "    # Label Encoder\n",
    "    le = LabelEncoder()\n",
    "    label_cols = ['meal_regime', 'nationality', 'reservation_Form',\n",
    "                'type_booked_room', 'reservation_Observations']\n",
    "    for col in label_cols:\n",
    "        dft[col] = le.fit_transform(dft[col])\n",
    "\n",
    "    # Ordinal Encoding\n",
    "    classificacao_dict = {'5 estrelas': 5, '4 estrelas': 4}\n",
    "    dft['hotel_rating'] = dft['hotel_rating'].map(classificacao_dict)\n",
    "\n",
    "    # Boolean\n",
    "    bool_cols = ['previously_hosted', 'tourism_agency_booking',\n",
    "                'company_booking', 'parking_Reservation']\n",
    "    for col in bool_cols:\n",
    "        dft[col] = dft[col].apply(\n",
    "            lambda x: 0 if x == 'Não' else 1 if x == 'Sim' else x)\n",
    "\n",
    "\n",
    "    # transform into int\n",
    "    dft['hotel_rating'] = dft['hotel_rating'].astype('int')\n",
    "    dft['previously_hosted'] = dft['previously_hosted'].astype('int')\n",
    "    dft['tourism_agency_booking'] = dft['tourism_agency_booking'].astype('int')\n",
    "    dft['company_booking'] = dft['company_booking'].astype('int')\n",
    "    dft['parking_Reservation'] = dft['parking_Reservation'].astype('int')\n",
    "    ## Predict\n",
    "    cols = ['id','hotel_rating','month_booking','nationality','parking_Reservation', 'reservation_Observations', 'number_stays_booking', 'reservation_Form']\n",
    "    y_pred_test = model.predict(dft[cols].values)\n",
    "\n",
    "    submission = pd.concat([listID, pd.Series(y_pred_test, name='Reserva Cancelada')], axis=1)\n",
    "\n",
    "    ## Create submission file\n",
    "    submission['Reserva Cancelada'] = submission['Reserva Cancelada'].astype(int)\n",
    "\n",
    "    submission.to_csv('../hachday_hotel-chain/submission/'+ name + '.csv', index=False)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../hachday_hotel-chain/dataset/X.csv')\n",
    "y = pd.read_csv('../hachday_hotel-chain/dataset/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Algoritmo  F1 Score\n",
      "0  Random Forest  0.957226\n",
      "1        XGBoost  0.957765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tabela = train_models(X_train, X_test, y_train, y_test)\n",
    "print(tabela)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 08-05-2023 17:20:51\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print('Start:',datetime.datetime.now().strftime('%d-%m-%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': [0.08,0.1,0.12],\n",
    "         'max_depth': [8,10,12],\n",
    "         'n_estimators': [800, 1000, 1200],\n",
    "         'subsample': [0.6,0.8, 1]}\n",
    "# Calculate weights\n",
    "\n",
    "# y array of weights\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y)\n",
    "\n",
    "# dict of weights\n",
    "n_classes = len(np.unique(y))\n",
    "weight_0 = len(y) / (n_classes * y.value_counts()[0])\n",
    "weight_1 = len(y) / (n_classes * y.value_counts()[1])\n",
    "class_weights = {0: weight_0, 1: weight_1}\n",
    "\n",
    "# use RandomizedSearchCV to find the best hyperparameter combination.\n",
    "random_search = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                                   param_distributions=param,\n",
    "                                   cv=5,\n",
    "                                   n_iter=16,\n",
    "                                   scoring='f1_macro',\n",
    "                                   random_state=32,\n",
    "                                   n_jobs=-1)\n",
    "random_search.fit(X.values, y.values, sample_weight=sample_weights)\n",
    "\n",
    "# print the best hyperparameter combination and its F-score (macro).\n",
    "print(\"Best hyperparameter:\", random_search.best_params_)\n",
    "print(f\"Best F-score (macro): {random_search.best_score_:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 05-04-2023 00:25:25\n",
      "Fine tuning execution time: 01:57:29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "duration = time.time()-t_start\n",
    "h = '{:02d}'.format(int(duration//3600))\n",
    "m = '{:02d}'.format(int((duration % 3600)//60))\n",
    "s = '{:02d}'.format(int(duration % 60))\n",
    "\n",
    "print('End:', datetime.datetime.now().strftime('%d-%m-%Y %H:%M:%S'))\n",
    "print(f'Fine tuning execution time: {h}:{m}:{s}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=10, n_estimators=1000, random_state=42,\n",
       "                           subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=10, n_estimators=1000, random_state=42,\n",
       "                           subsample=0.8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=10, n_estimators=1000, random_state=42,\n",
       "                           subsample=0.8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "np.seterr(all='ignore')\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y)\n",
    "# model definition\n",
    "xgb_model = GradientBoostingClassifier(max_depth=10, n_estimators=1000, random_state=42, subsample=0.8)\n",
    "\n",
    "# model training\n",
    "xgb_model.fit(X.values, y.values, sample_weight=sample_weights)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Kaggle Submission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../hachday_hotel-chain/dataset/test.csv', low_memory=False)\n",
    "listID = df_test['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_test.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfomation_test(model =  xgb_model, dft = dft, listID= listID, name = 'submission_v3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Versão</th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>f1_score_test</th>\n",
       "      <th>private_score</th>\n",
       "      <th>public_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>regressionLogitic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1</td>\n",
       "      <td>XBGoost</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2</td>\n",
       "      <td>XBGoost</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Versão          Algoritmo  f1_score_test  private_score  public_score\n",
       "0  baseline  regressionLogitic            NaN          0.669         0.669\n",
       "1        v1            XBGoost          0.971          0.883         0.881\n",
       "2        v2            XBGoost          0.968          0.912         0.911"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_kaggle = pd.DataFrame(columns = ['Versão','Algoritmo','f1_score_test','private_score', 'public_score'])\n",
    "\n",
    "baseline = {'Versão':'baseline','Algoritmo':'regressionLogistic','private_score':0.669, 'public_score':0.669}\n",
    "model_v1 = {'Versão': 'v1', 'Algoritmo':'XGBoost','f1_score_test': 0.971, 'private_score': 0.883, 'public_score': 0.881}\n",
    "model_v2 = {'Versão': 'v2', 'Algoritmo':'XGBoost', 'f1_score_test': 0.968, 'private_score': 0.912, 'public_score': 0.911}\n",
    "\n",
    "\n",
    "modelos = [baseline, model_v1, model_v2]\n",
    "result_kaggle.append(modelos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
